{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_page(url):#请求函数：获取某一网页上的所有内容\n",
    "    headers = {\n",
    "    'User-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36',\n",
    "    'Host' : 'weibo.cn',\n",
    "    'Accept' : 'application/json, text/plain, */*',\n",
    "    'Accept-Language' : 'zh-CN,zh;q=0.9',\n",
    "    'Accept-Encoding' : 'gzip, deflate, br',\n",
    "    'Cookie' : '_T_WM=56599902299; SCF=AhB2sojzjN0zQkdXGNZc8xjYsYhgOhbzyqPAfhHYUr_4SHxbj58wtDfVSctEkdABYSEQhMapT9K-eP-o3zlFdl4.; MLOGIN=1; SUB=_2A25x-IU4DeRhGeVI61AY8yrFzz-IHXVTAitwrDV6PUJbkdAKLUf5kW1NTA5YGEyc1WDmUND7hTleB551pHz6iyen; SUHB=079jWxx9Q6MmS7; SSOLoginState=1560081768; M_WEIBOCN_PARAMS=oid%3D4360941451950470%26luicode%3D20000061%26lfid%3D4360941451950470; XSRF-TOKEN=e038f9; _T_WL=1; _WEIBO_UID=3602934943',\n",
    "    'DNT' : '1',\n",
    "    'Connection' : 'keep-alive'\n",
    "     }#请求头的书写，包括User-agent,Cookie等\n",
    "    response = requests.get(url,headers = headers,verify=False)#利用requests.get命令获取网页html\n",
    "    if response.status_code == 200:#状态为200即为爬取成功\n",
    "        return response.text#返回值为html文档，传入到解析函数当中\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_one_page(html):#解析html并存入到文档result.txt中\n",
    "    pattern_time = re.compile('<span class=\"ct\">.*?&nbsp;', re.S)\n",
    "    pattern_comment = re.compile('<span class=\"ctt\">.*?</a></span>', re.S)\n",
    "    items_time = re.findall(pattern_time,html)\n",
    "    items_comment = re.findall(pattern_comment,html)\n",
    "    data = pd.DataFrame(items_time, items_comment)\n",
    "    data.to_csv('weibo.csv', header = False, mode='a+',encoding = \"GB18030\")\n",
    "    #result = str(items)\n",
    "    #with open('test.txt','a',encoding='GB18030') as fp:\n",
    "    #    fp.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "快乐的郑虫正在爬取第 501 页评论\n",
      "快乐的郑虫正在爬取第 502 页评论\n",
      "快乐的郑虫正在爬取第 503 页评论\n",
      "快乐的郑虫正在爬取第 504 页评论\n",
      "快乐的郑虫正在爬取第 505 页评论\n",
      "快乐的郑虫正在爬取第 506 页评论\n",
      "快乐的郑虫正在爬取第 507 页评论\n",
      "快乐的郑虫正在爬取第 508 页评论\n",
      "快乐的郑虫正在爬取第 509 页评论\n",
      "快乐的郑虫正在爬取第 510 页评论\n"
     ]
    }
   ],
   "source": [
    "#爬取工作量大，只展示10页的爬取，爬取结果为weibo.csv\n",
    "#最终的完整爬取结果为df.csv\n",
    "for i in range(500,510):\n",
    "    url = \"https://weibo.cn/comment/HpzmF8bpc?uid=2145291155&rl=0&page=\"+str(i)\n",
    "    requests.packages.urllib3.disable_warnings()\n",
    "    html = get_one_page(url)\n",
    "    print('快乐的郑虫正在爬取第 %d 页评论' % (i+1))\n",
    "    parse_one_page(html)\n",
    "    time.sleep(random.uniform(1,3))#每次循环后随机停顿1-3秒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
